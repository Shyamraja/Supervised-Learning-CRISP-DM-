{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All packages needed for this project are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization packages - matplotlib and seaborn\n",
    "# Remember that pandas is also handy and capable when it comes to plotting!\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine learning package - scikit-learn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "# Show the plots inline in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color = lightcoral>1. Classification using k-nearest neighbors </font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start exploring the world of data modeling by using the <font color = lightcoral>K-Nearest Neightbors (k-NN) algorithm</font>. The k-NN algorithm is one of the classic supervised machine learning algorithms which assumes that similar points are close to each other. \n",
    "\n",
    "In our case, we'll use the k-NN algorithm to *predict the presence of cardiovascular disease* (CVD) using all the other variables as <font color = lightcoral>features</font> in the given data set. I.e. the <font color = lightcoral>target variable</font> that we are interested in is `cardio`.\n",
    "\n",
    "But first, we need data for the task. The code for loading the data into the environment is provided for you. The code should work but make sure that you have the CSV file of the data in the same directory where you have this notebook file.\n",
    "\n",
    "**Exercise 1 A)**\n",
    "\n",
    "Take a random sample of 1500 rows from the dataframe using your id as a seed. Print the first 15 rows to check that everything is ok with the dataframe.\n",
    "\n",
    "*Note: as mentioned, the data remains the same, but cholesterol has been one-hot-encoded for you already. There's also a new variable, gluc (about glucose levels), which is one-hot-encoded for you. It has similar values as cholesterol originally had [normal, at risk, elevated].*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path for the data\n",
    "data_path = 'ex2_cardio_data.csv'\n",
    "\n",
    "# Read the CSV file \n",
    "cardio_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>cholesterol_normal</th>\n",
       "      <th>cholesterol_elevated</th>\n",
       "      <th>cholesterol_high</th>\n",
       "      <th>gluc_normal</th>\n",
       "      <th>gluc_elevated</th>\n",
       "      <th>gluc_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>80.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3584</th>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>94.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3380</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>100.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>59.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5646</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>154</td>\n",
       "      <td>72.0</td>\n",
       "      <td>180</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>70.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>65.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1720</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>51.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4462</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>110.0</td>\n",
       "      <td>140</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>68.0</td>\n",
       "      <td>103</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>83.0</td>\n",
       "      <td>80</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4686</th>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>176</td>\n",
       "      <td>108.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>65.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>155</td>\n",
       "      <td>52.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  cardio  \\\n",
       "560    55       1     163    80.0    110     80      0     0       0       0   \n",
       "3584   62       1     156    94.0    120     80      0     0       1       0   \n",
       "3380   54       1     158   100.0    130     90      0     0       1       0   \n",
       "1535   51       2     169    59.0    110     70      0     0       1       0   \n",
       "5646   63       1     154    72.0    180    100      0     0       1       1   \n",
       "328    46       1     168    70.0    120     80      0     0       0       0   \n",
       "2269   45       1     160    60.0    120     80      0     0       1       0   \n",
       "2130   57       1     165    65.0    120     80      0     0       0       0   \n",
       "1720   41       1     162    51.0    120     80      1     1       1       0   \n",
       "4462   40       1     157   110.0    140     80      0     0       1       1   \n",
       "1206   58       1     151    68.0    103     64      0     0       1       0   \n",
       "2259   59       1     160    83.0     80    120      0     0       1       0   \n",
       "4686   52       2     176   108.0    130     80      0     0       1       1   \n",
       "5259   59       1     158    65.0    110     80      0     0       1       1   \n",
       "2567   57       1     155    52.0    110     70      0     0       1       0   \n",
       "\n",
       "      cholesterol_normal  cholesterol_elevated  cholesterol_high  gluc_normal  \\\n",
       "560                    1                     0                 0            1   \n",
       "3584                   1                     0                 0            1   \n",
       "3380                   0                     0                 1            0   \n",
       "1535                   0                     1                 0            1   \n",
       "5646                   0                     0                 1            0   \n",
       "328                    1                     0                 0            1   \n",
       "2269                   1                     0                 0            1   \n",
       "2130                   1                     0                 0            1   \n",
       "1720                   1                     0                 0            1   \n",
       "4462                   1                     0                 0            1   \n",
       "1206                   1                     0                 0            1   \n",
       "2259                   1                     0                 0            1   \n",
       "4686                   0                     0                 1            0   \n",
       "5259                   0                     1                 0            1   \n",
       "2567                   1                     0                 0            1   \n",
       "\n",
       "      gluc_elevated  gluc_high  \n",
       "560               0          0  \n",
       "3584              0          0  \n",
       "3380              0          1  \n",
       "1535              0          0  \n",
       "5646              0          1  \n",
       "328               0          0  \n",
       "2269              0          0  \n",
       "2130              0          0  \n",
       "1720              0          0  \n",
       "4462              0          0  \n",
       "1206              0          0  \n",
       "2259              0          0  \n",
       "4686              1          0  \n",
       "5259              0          0  \n",
       "2567              0          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining student_id ass the seed for sampling to ensure getting the random sample\n",
    "my_id = 2310107\n",
    "#Sampling the data\n",
    "sample_cardio_data = cardio_data.sample(n=1500, random_state=my_id)\n",
    "# print first 15 rows of sampled data\n",
    "sample_cardio_data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "      <th>cholesterol_normal</th>\n",
       "      <th>cholesterol_elevated</th>\n",
       "      <th>cholesterol_high</th>\n",
       "      <th>gluc_normal</th>\n",
       "      <th>gluc_elevated</th>\n",
       "      <th>gluc_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>104.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>160</td>\n",
       "      <td>59.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>77.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>80.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>41.0</td>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>152</td>\n",
       "      <td>56.0</td>\n",
       "      <td>103</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>167</td>\n",
       "      <td>67.0</td>\n",
       "      <td>110</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>70.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>67.0</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>92.0</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>169</td>\n",
       "      <td>69.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>68.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "      <td>69.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "      <td>80.0</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  cardio  \\\n",
       "0    48       1     170   104.0    120     80      0     0       1       0   \n",
       "1    51       0     160    59.0    110     80      0     0       1       0   \n",
       "2    42       1     166    77.0    120     80      0     0       1       0   \n",
       "3    55       0     168    80.0    120     80      0     0       1       0   \n",
       "4    57       0     154    41.0    806      0      0     0       1       0   \n",
       "5    53       0     152    56.0    103     65      0     0       1       0   \n",
       "6    42       0     167    67.0    110     70      0     0       1       0   \n",
       "7    41       1     172    70.0    110     80      0     0       1       0   \n",
       "8    43       1     169    67.0    100     80      0     0       1       0   \n",
       "9    39       1     168    60.0    120     80      0     0       1       0   \n",
       "10   60       0     168    92.0    130     90      0     0       1       0   \n",
       "11   58       1     169    69.0    120     80      0     0       0       0   \n",
       "12   44       0     164    68.0    120     80      0     0       0       0   \n",
       "13   52       0     169    69.0    120     80      0     0       1       0   \n",
       "14   58       0     164    80.0    130     80      0     0       1       0   \n",
       "\n",
       "    cholesterol_normal  cholesterol_elevated  cholesterol_high  gluc_normal  \\\n",
       "0                    1                     0                 0            1   \n",
       "1                    0                     1                 0            1   \n",
       "2                    1                     0                 0            1   \n",
       "3                    1                     0                 0            1   \n",
       "4                    1                     0                 0            1   \n",
       "5                    1                     0                 0            1   \n",
       "6                    1                     0                 0            1   \n",
       "7                    1                     0                 0            1   \n",
       "8                    1                     0                 0            1   \n",
       "9                    1                     0                 0            0   \n",
       "10                   0                     0                 1            0   \n",
       "11                   1                     0                 0            1   \n",
       "12                   1                     0                 0            1   \n",
       "13                   1                     0                 0            1   \n",
       "14                   1                     0                 0            0   \n",
       "\n",
       "    gluc_elevated  gluc_high  \n",
       "0               0          0  \n",
       "1               0          0  \n",
       "2               0          0  \n",
       "3               0          0  \n",
       "4               0          0  \n",
       "5               0          0  \n",
       "6               0          0  \n",
       "7               0          0  \n",
       "8               0          0  \n",
       "9               1          0  \n",
       "10              0          1  \n",
       "11              0          0  \n",
       "12              0          0  \n",
       "13              0          0  \n",
       "14              0          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import LabelEncoder\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "cardio_data['gender'] = encoder.fit_transform(cardio_data['gender'])\n",
    "cardio_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We have the data so now, let's put it to use. \n",
    "To teach the k-NN algorithm (or any other machine learning algorithm) to recognize patterns, we need <font color = lightcoral>training data</font>. However, to assess how well a model has learned these patterns, we require <font color = lightcoral>test data</font> which is new and unseen by the trained model. It's important to note that the test set is not revealed to the model until after the training is complete.\n",
    "\n",
    "So, to *estimate the performance of a model*, we may use a basic <font color = lightcoral>train-test split</font>. The term \"split\" is there because we literally split the data into two sets.\n",
    "\n",
    "**Exercise 1 B)**\n",
    "\n",
    "Collect the features as an array named `features`, and the target variable as an array named `labels`. Create training and test data by randomly splitting the data into training (80%) and test (20%) sets.\n",
    "\n",
    "- Do you need stratification for our dataset? Explain your decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cardio\n",
      "0    4200\n",
      "1    1800\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### Code - Train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "features = cardio_data[['age',\n",
    "             'gender',\n",
    "             'height',\n",
    "             'weight',\n",
    "             'ap_hi',\n",
    "             'ap_lo',\n",
    "             'smoke',\n",
    "             'alco',\n",
    "             'active',\n",
    "             'cholesterol_normal',\n",
    "             'cholesterol_elevated',\n",
    "             'cholesterol_high',\n",
    "             'gluc_normal',\n",
    "             'gluc_elevated',\n",
    "             'gluc_high']]\n",
    "labels = cardio_data['cardio']\n",
    "\n",
    "# random_state is used to ensure random split is reproducible 80% trainin set and 20% test set\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.2,random_state=42, stratify = labels)\n",
    "\n",
    "#Checking the balance of target variable\n",
    "print(cardio_data['cardio'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  \\\n",
      "297    52       1     170    75.0    120     80      0     0       1   \n",
      "572    51       0     169    82.0    120     80      0     0       1   \n",
      "2295   45       1     167    69.0    110     70      0     0       0   \n",
      "5457   44       0     155    59.0    120     80      0     0       1   \n",
      "4493   53       1     171    74.0    120     80      0     0       1   \n",
      "\n",
      "      cholesterol_normal  cholesterol_elevated  cholesterol_high  gluc_normal  \\\n",
      "297                    1                     0                 0            1   \n",
      "572                    1                     0                 0            1   \n",
      "2295                   1                     0                 0            1   \n",
      "5457                   1                     0                 0            1   \n",
      "4493                   1                     0                 0            1   \n",
      "\n",
      "      gluc_elevated  gluc_high  \n",
      "297               0          0  \n",
      "572               0          0  \n",
      "2295              0          0  \n",
      "5457              0          0  \n",
      "4493              0          0  \n"
     ]
    }
   ],
   "source": [
    "#checking features trained data heads\n",
    "print(features_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      age  gender  height  weight  ap_hi  ap_lo  smoke  alco  active  \\\n",
      "297    52       1     170    75.0    120     80      0     0       1   \n",
      "572    51       0     169    82.0    120     80      0     0       1   \n",
      "2295   45       1     167    69.0    110     70      0     0       0   \n",
      "5457   44       0     155    59.0    120     80      0     0       1   \n",
      "4493   53       1     171    74.0    120     80      0     0       1   \n",
      "\n",
      "      cholesterol_normal  cholesterol_elevated  cholesterol_high  gluc_normal  \\\n",
      "297                    1                     0                 0            1   \n",
      "572                    1                     0                 0            1   \n",
      "2295                   1                     0                 0            1   \n",
      "5457                   1                     0                 0            1   \n",
      "4493                   1                     0                 0            1   \n",
      "\n",
      "      gluc_elevated  gluc_high  \n",
      "297               0          0  \n",
      "572               0          0  \n",
      "2295              0          0  \n",
      "5457              0          0  \n",
      "4493              0          0  \n",
      "297     0\n",
      "572     0\n",
      "2295    0\n",
      "5457    1\n",
      "4493    1\n",
      "Name: cardio, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#checking features train data heads\n",
    "print(features_train.head())\n",
    "#checking labes train data heads\n",
    "print(labels_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Train and Test cardio Mean\n",
      "0.3 0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"For Train and Test cardio Mean\")\n",
    "print(labels_train.mean(), labels_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Stratification Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the sampled cardio Data:\n",
      "cardio\n",
      "0    0.706667\n",
      "1    0.293333\n",
      "Name: proportion, dtype: float64\n",
      "In the Origional cardio Data:\n",
      "cardio\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " In Training Set:\n",
      "cardio\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " In Test Set:\n",
      "cardio\n",
      "0    0.7\n",
      "1    0.3\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Checking In the original data\n",
    "print(\"In the sampled cardio Data:\")\n",
    "print(sample_cardio_data['cardio'].value_counts(normalize=True))\n",
    "\n",
    "# Checking In the original data\n",
    "print(\"In the Origional cardio Data:\")\n",
    "print(cardio_data['cardio'].value_counts(normalize=True))\n",
    "\n",
    "# In the training set\n",
    "print(\"\\n In Training Set:\")\n",
    "print(labels_train.value_counts(normalize=True))\n",
    "\n",
    "# In the test set\n",
    "print(\"\\n In Test Set:\")\n",
    "print(labels_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = lightcoral> The value counts data shows about 70% samples belongs to class 0 and 30% beongs to class 1 so the data is slightly imbalanced but the class distribution shows consistent pattern in all data sample.The stratification in train_test_split did work correctly.So we don't need here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "**Exercise 1 C)** \n",
    "\n",
    "Standardize the numerical features: Note that you should now have two separate features that you've divided all the features into.\n",
    "\n",
    "- Describe how the k-NN model would make predictions about whether or not a patient has a CVD when the features are not standardized, and explain the reasons behind.\n",
    "\n",
    "\n",
    "*Note: Some good information about preprocessing and how to use it for train and test data can be found https://scikit-learn.org/stable/modules/preprocessing.html*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cholesterol_normal</th>\n",
       "      <th>cholesterol_elevated</th>\n",
       "      <th>cholesterol_high</th>\n",
       "      <th>gluc_normal</th>\n",
       "      <th>gluc_elevated</th>\n",
       "      <th>gluc_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.013537</td>\n",
       "      <td>1</td>\n",
       "      <td>0.661544</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>-0.034354</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>-0.159885</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541007</td>\n",
       "      <td>0.623197</td>\n",
       "      <td>-0.034354</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>-1.037969</td>\n",
       "      <td>1</td>\n",
       "      <td>0.299935</td>\n",
       "      <td>-0.301573</td>\n",
       "      <td>-0.083750</td>\n",
       "      <td>-0.127345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5457</th>\n",
       "      <td>-1.184317</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.146502</td>\n",
       "      <td>-1.012935</td>\n",
       "      <td>-0.034354</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4493</th>\n",
       "      <td>0.132810</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782080</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>-0.034354</td>\n",
       "      <td>-0.067929</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  gender    height    weight     ap_hi     ap_lo  smoke  alco  \\\n",
       "297  -0.013537       1  0.661544  0.125244 -0.034354 -0.067929      0     0   \n",
       "572  -0.159885       0  0.541007  0.623197 -0.034354 -0.067929      0     0   \n",
       "2295 -1.037969       1  0.299935 -0.301573 -0.083750 -0.127345      0     0   \n",
       "5457 -1.184317       0 -1.146502 -1.012935 -0.034354 -0.067929      0     0   \n",
       "4493  0.132810       1  0.782080  0.054108 -0.034354 -0.067929      0     0   \n",
       "\n",
       "      active  cholesterol_normal  cholesterol_elevated  cholesterol_high  \\\n",
       "297        1                   1                     0                 0   \n",
       "572        1                   1                     0                 0   \n",
       "2295       0                   1                     0                 0   \n",
       "5457       1                   1                     0                 0   \n",
       "4493       1                   1                     0                 0   \n",
       "\n",
       "      gluc_normal  gluc_elevated  gluc_high  \n",
       "297             1              0          0  \n",
       "572             1              0          0  \n",
       "2295            1              0          0  \n",
       "5457            1              0          0  \n",
       "4493            1              0          0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define numerical and binary features\n",
    "numerical_features = ['age', 'height', 'weight', 'ap_hi', 'ap_lo']\n",
    "binary_features    = ['gender', 'smoke', 'alco', 'active', 'cholesterol_normal', \n",
    "                      'cholesterol_elevated', 'cholesterol_high', 'gluc_normal', \n",
    "                      'gluc_elevated', 'gluc_high']\n",
    "\n",
    "# Function to fit the scaler\n",
    "def fit_scaler(features_train, numerical_features):\n",
    "    scaler = StandardScaler().fit(features_train[numerical_features])\n",
    "    return scaler\n",
    "\n",
    "# Function to scale the features of numerical data\n",
    "def scale_features(features, numerical_features, scaler):\n",
    "    features_scale = features.copy(deep=True)\n",
    "    features_scale[numerical_features] = scaler.transform(features[numerical_features])\n",
    "    return features_scale\n",
    "\n",
    "# Fit the scaler using the training data\n",
    "scaler = fit_scaler(features_train, numerical_features)\n",
    "\n",
    "# Scale the training and test data\n",
    "features_train_scale = scale_features(features_train, numerical_features, scaler)\n",
    "features_test_scale = scale_features(features_test, numerical_features, scaler)\n",
    "\n",
    "#Checking the features scale trained data\n",
    "features_train_scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = lightcoral> The k-NN model is distance based algorithm. The model assigns the new instance based on labels of nearest neighbours.For non standardized features the larger scale will dominate the distance calculation and effect the accuraty of prediction.Comparing the centimeters and kilometers the feature in kms will have smaller range of values and will have less impact on distance. So standardization before applying k-NN model is important because the standardized data make k-NN model more accurate predictions.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "It's time for us to train the model!\n",
    "\n",
    "**Exercise 1 D)**\n",
    "\n",
    "Train a k-NN model with $k=3$. Print out the confusion matrix and use it to compute the accuracy, the precision and the recall.\n",
    "- What does each cell in the confusion matrix represents in the context of our dataset?\n",
    "- How does the model perform with the different classes? Where do you think the differences come from? Interpret the performance metrics you just computed.\n",
    "- With our dataset, why should you be a little more cautious when interpreting the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[705 135]\n",
      " [187 173]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.73\n",
      "Precision: 0.72\n",
      "Recall: 0.73\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create and fit the k-NN model\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(features_train, labels_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predict = knn_model.predict(features_test)\n",
    "\n",
    "#calculating the predicted probabilities of the positive class \n",
    "y_predict_probas = knn_model.predict_proba(features_test)[:,1]\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(labels_test, y_predict, labels=knn_model.classes_)\n",
    "print(f\"Confusion Matrix:\\n {conf_matrix}\")\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=knn_model.classes_)\n",
    "cm_display.plot()\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = accuracy_score(labels_test, y_predict)\n",
    "precision = precision_score(labels_test, y_predict, average='weighted')\n",
    "recall = recall_score(labels_test, y_predict, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = lightcoral> \n",
    "1)Bottom right 173 is true positive.Top left 705 means True (negative)0 class. Top right 135 represents false positives class.Bottom left 187 is false negatives.\n",
    "\n",
    "\n",
    "2)Model perform well with class 0 lack with class 1.The accuracy of the model is 0.73. This means that 73% of the total predictions made by the model are correct.The precision is 0.72 suggests 72% of the positive predictions made by the model are actually positive. The recall 0.73 means that the model correctly identified 74% of the actual positives.\n",
    " \n",
    " \n",
    "3)In our data imbalance of class can create in misleading of accuracy.It is also affected by evaluation metrics  \n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "You randomly divided the data into two sets, one for training the k-NN model and the other for evaluating its performance. However, randomness is not the thing we really need, and in fact, it's not something we even desire. Instead, what we do want is to keep track of each step we're making and exporing. This said, the *reproducibility* of the results is extremely important in research. To achieve this, we can utilize <font color = lightcoral> a random seed</font>, with which we can re-run the codes and get the exact same results than before.\n",
    "\n",
    "For example, we can use a fixed seed when we're shuffling the data before splitting it into training and test sets. This ensures that when we're re-runing the code, we obtain exactly the same partitions of the data in each split.\n",
    "\n",
    "**Exercise 1 E)**\n",
    "\n",
    "Initialize 1000 random seeds and continue with the k-NN model ($k=3$): Perform 1000 different train-test splits using these seeds and store the accuracies from each split. Plot the accuracies in a histogram, and discuss your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_seeds = np.random.randint(1, 10000, size=1000)\n",
    "\n",
    "# Storing the accuracies from each split\n",
    "accuracies = []\n",
    "\n",
    "# Perform 1000 train-test splits using different seeds\n",
    "for seed in random_seeds:\n",
    "    # Splitting the data\n",
    "    (random_features_train, random_features_test, random_labels_train, random_labels_test )= train_test_split(features_train, labels_train, test_size=0.2, random_state=seed)\n",
    "    \n",
    "    # Initialization of the k-NN model\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "    # Train the model\n",
    "    knn.fit(random_features_train, random_labels_train)\n",
    "\n",
    "    # Making the predictions\n",
    "    y_pred = knn.predict(random_features_test)\n",
    "\n",
    "    # Calculate accuracy and store it\n",
    "    accuracy = accuracy_score(random_labels_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Plot the accuracies in a histogram\n",
    "plt.hist(accuracies, bins=20, color='blue')\n",
    "plt.axvline(np.mean(accuracies), color='black', label='Mean Accuracy')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of k-NN Model Accuracies')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Printing the mean accuracy\n",
    "print(\"Mean Accuracy:\", np.mean(accuracies))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
